{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"CNN Kullanarak Görüntü Sınıflandırma\n\nBu projede, görüntü sınıflandırmak için bir Konvolüsyonel Sinir Ağı (CNN) modeli oluşturacağız. Modeli oluşturmak için TensorFlow ve Keras kütüphanelerini kullanacağız. Veri seti eğitim ve test olarak ikiye ayrılacak ve görüntü ön işleme teknikleriyle modelin doğruluğunu artırmayı hedefleyeceğiz.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\nfrom PIL import Image\nimport os\nimport warnings\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"numpy ve pandas: Veri ve matris işlemleri için kullanılır.\n\nmatplotlib ve seaborn: Veri kümesini ve model performans metriklerini görselleştirmek için kullanılır.\n\ntrain_test_split: Veriyi eğitim ve test setlerine ayırmak için kullanılır.\n\nconfusion_matrix ve classification_report: Modelin sınıflandırma performansını değerlendirmek için kullanılır.\n\nSequential, Dense, Dropout, Flatten, Conv2D, MaxPooling2D: CNN modelini oluşturmak için gerekli katmanlar.\n\nImageDataGenerator: Modeli eğitirken gerçek zamanlı veri artırımı sağlar.\n\nLabelEncoder ve to_categorical: Kategorik etiketleri sayısal verilere dönüştürmek için kullanılır.\n\nPIL kütüphanesi: Görüntü işlemleri için kullanılır.","metadata":{}},{"cell_type":"code","source":"# Uyarıları yok say\nwarnings.filterwarnings('ignore')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bazı gereksiz uyarıları yok sayarak çıktının daha temiz olmasını sağlayacağız.","metadata":{}},{"cell_type":"code","source":"# Kaggle veri seti yolu\nfish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veri setinin dosya yolunu tanımlıyoruz. Veri seti Kaggle ortamında bulunduğundan, dosya yolunu belirtmemiz lazım.","metadata":{}},{"cell_type":"code","source":"# Etiket ve yol listelerini tanımla\nlabels = []\npaths = []\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu adımda, etiketler (hangi tür balık olduğu) ve resim yollarını depolamak için iki liste oluşturuyoruz.","metadata":{}},{"cell_type":"code","source":"# Klasörlerde gezinip her resmin yolunu ve etiketini kaydet\nfor dir_name, _, filenames in os.walk(fish_dir):\n    for filename in filenames:\n        if filename.endswith('.png') and 'GT' not in dir_name:\n            labels.append(os.path.split(dir_name)[-1])\n            paths.append(os.path.join(dir_name, filename))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu adımda, veri seti klasörlerinin içinde gezinerek her resmin yolunu ve etiketini topluyoruz. Her balık türü ayrı bir klasörde olduğu için, klasör ismi etiketi temsil ediyor.\n\nos.walk: Belirtilen dizinde tüm alt dizinleri ve dosyaları döner.\n\npng uzantısına sahip dosyaları alırız, çünkü veri setimizdeki resimler bu formatta.\n\n'GT': 'GT' içeren klasörleri hariç tutuyoruz (genellikle bu tür klasörler \"ground truth\" içindir).","metadata":{}},{"cell_type":"code","source":"# Pandas DataFrame'e dönüştür\ndata = pd.DataFrame({'path': paths, 'label': labels})\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Topladığımız yolları ve etiketleri bir DataFrame'e dönüştürüyoruz. Bu, veriyi organize bir formatta tutmamızı sağlar.\n\npath: Görüntü dosyalarının yolları.\nlabel: Görüntülerin etiketleri (balık türleri).","metadata":{}},{"cell_type":"code","source":"# Resimleri yükleme fonksiyonu\ndef load_images(data, img_size=(128, 128)):\n    images = []\n    for path in data['path']:\n        img = Image.open(path)\n        img = img.resize(img_size)\n        img_array = np.array(img) / 255.0\n        if len(img_array.shape) == 2:  # Eğer grayscale ise\n            img_array = np.stack([img_array]*3, axis=-1)\n        images.append(img_array)\n    return np.array(images)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu adımda, her resmin yolunu alıp resimleri belirli bir boyutta yeniden boyutlandıran ve normalize eden bir fonksiyon tanımlıyoruz. Eğer görüntüler gri tonlamalıysa, bunları 3 kanallı RGB formatına dönüştürüyoruz.\n\nimg_size: Resimlerin yeniden boyutlandırılacağı hedef boyut (örneğin 128x128 piksel).\n\nimg_array / 255.0: Her bir pikseli [0, 1] aralığına getiririz, böylece model daha iyi öğrenir.","metadata":{}},{"cell_type":"code","source":"# Görselleri yükle (Bellek problemi varsa ImageDataGenerator kullanın)\nX = load_images(data)\ny = data['label']\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resimleri yüklemek için daha önce tanımladığımız load_images fonksiyonunu çağırıyoruz\n\nX: Resim verilerinin numpy dizisi.\n\ny: Etiketler.","metadata":{}},{"cell_type":"code","source":"# Etiketleri sayısal değerlere dönüştür\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\ny_categorical = to_categorical(y_encoded)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Makine öğrenmesi algoritmalarında genellikle etiketler sayısal olarak ifade edilir. Bu adımda, etiketlerimizi sayısal değerlere dönüştürüyoruz ve sonrasında bu değerleri one-hot encoding (tek-sıcak kodlama) yaparak her sınıfı ayrı bir vektör olarak ifade ediyoruz.\n\nLabelEncoder: Etiketleri sayısal değerlere dönüştürür.\n\nto_categorical: Sayısal etiketleri one-hot encoding formuna dönüştürür.","metadata":{}},{"cell_type":"code","source":"# Train-test verisini ayır\nX_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veri setimizi %80 eğitim, %20 test olacak şekilde ayırıyoruz.\n\ntrain_test_split: Veri setini eğitim ve test olarak böler. test_size=0.2 parametresi, verinin %20'sinin test setine ayrılmasını sağlar.\n\n\n","metadata":{}},{"cell_type":"code","source":"# Veri artırıcı kullanarak veri yükleme ve augmentasyon (alternatif yöntem)\ndatagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n                             horizontal_flip=True, fill_mode='nearest')\n\ndatagen.fit(X_train)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veri artırıcı kullanarak görüntüler üzerinde çeşitli dönüşümler yapıyoruz. Bu sayede modelin genelleme yeteneği artıyor.\n\nrotation_range: Görüntüleri belirli bir aralıkta döndürür.\n\nwidth_shift_range ve height_shift_range: Görüntüleri yatay ve dikey olarak kaydırır.\n\nhorizontal_flip: Görüntüleri yatay olarak çevirir.","metadata":{}},{"cell_type":"code","source":"# Modelin tanımlanması\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(label_encoder.classes_), activation='softmax'))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN modeli tanımlanıyor. İki konvolüsyon katmanı ve ardından havuzlama katmanları, ardından tam bağlantılı katmanlar ekleniyor.\n\nConv2D: Konvolüsyonel katman, özellikleri öğrenir.\n\nMaxPooling2D: Boyutları küçültür ve en belirgin özellikleri öne çıkarır.\n\nDense: Tam bağlantılı katman, sınıflandırma işlemi yapar.\n\nDropout: Aşırı öğrenmeyi engellemek için belirli nöronları rastgele sıfırlar.\n\nsoftmax: Çıkış katmanında, sınıflandırma için kullanılır.\n\n","metadata":{}},{"cell_type":"code","source":"# Modelin derlenmesi\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modeli adam optimizasyon algoritması ve kategorik çapraz entropi kaybı fonksiyonu ile derliyoruz.\n\nadam: Optimizasyon algoritması, ağırlıkları günceller.\n\ncategorical_crossentropy: Çok sınıflı sınıflandırma problemlerinde kullanılan kayıp fonksiyonu.\n\n","metadata":{}},{"cell_type":"code","source":"# Modeli eğitme (data generator kullanarak)\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n                    validation_data=(X_test, y_test), epochs=20)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modeli veri artırıcı kullanarak eğitiyoruz ve doğrulama seti ile performansını değerlendiriyoruz.\n\ndatagen.flow: Veri artırıcı ile eğitim verilerini besler.\n\nepochs: Modelin kaç defa eğitim seti üzerinde eğitileceğini belirtir.\n\nvalidation_data: Eğitim sırasında doğrulama seti ile modelin performansını izler.","metadata":{}},{"cell_type":"code","source":"# Modeli değerlendirme\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test seti üzerinde tahminler yaparak modelin performansını değerlendiriyoruz.\n\npredict: Test seti üzerinde tahmin yapar.\n\nnp.argmax: One-hot encoded vektörleri sınıf etiketlerine dönüştürür.","metadata":{}},{"cell_type":"code","source":"# Confusion matrix\nconf_matrix = confusion_matrix(y_true, y_pred_classes)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelin sınıflandırma başarısını görselleştirmek için karışıklık matrisi oluşturuyoruz.\n\nconfusion_matrix: Modelin hangi sınıfları doğru veya yanlış sınıflandırdığını gösterir.\n\nsns.heatmap: Matrisin görselleştirilmesi.","metadata":{}},{"cell_type":"code","source":"# Classification report\nprint(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Her sınıf için doğruluk, geri çağırma, F1 skoru gibi metrikleri içeren bir rapor oluşturuyoruz.\n\n","metadata":{}},{"cell_type":"code","source":"# Accuracy grafiği\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelin eğitim ve doğrulama sırasında elde ettiği doğruluk oranlarını görselleştiriyoruz.\n\n","metadata":{}},{"cell_type":"code","source":"# Kayıp fonksiyonu grafiği\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Eğitim ve doğrulama sırasında modelin kayıp fonksiyon değerlerini görselleştiriyoruz.\n\n","metadata":{}},{"cell_type":"code","source":"# Hiperparametre optimizasyonu için dropout oranı ve optimizer değişiklikleri\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(label_encoder.classes_), activation='softmax'))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelde kullanılan dropout oranını ve optimizasyon algoritmasını değiştirerek modelin daha iyi performans göstermesini sağlamaya çalışıyoruz.\n\nDropout(0.4): Dropout oranını artırarak daha fazla nöron sıfırlıyoruz.\n\nrmsprop: Optimizasyon algoritmasını rmsprop olarak değiştiriyoruz.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n                    validation_data=(X_test, y_test), epochs=20)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yeni dropout oranı ve optimizasyon algoritması ile modeli tekrar eğitiyoruz.\n\nrmsprop: Daha iyi bir öğrenme hızına sahip alternatif bir optimizasyon algoritmasıdır.","metadata":{}}]}